# Default values for skywalking.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

serviceAccounts:
  oap:

oap:
  name: skywalking-oap
  image:
    repository: apache/skywalking-oap-server
    tag: 6.4.0
    pullPolicy: IfNotPresent
  ports:
    grpc: 11800
    rest: 12800
  replicas: 2
  service:
    type: ClusterIP
  javaOpts: -Xmx2g -Xms2g
  antiAffinity: "soft"
  nodeAffinity: {}
  nodeSelector: {}
  tolerations: []
  resources: {}
    # limits:
    #   cpu: 8
    #   memory: 8Gi
    # requests:
    #   cpu: 8
    #   memory: 4Gi
  # podAnnotations:
  #   example: oap-foo
  envoy:
    als:
      enabled: false
      # more envoy ALS ,please refer to https://github.com/apache/skywalking/blob/master/docs/en/setup/envoy/als_setting.md#observe-service-mesh-through-als
  env:
    # more env, please refer to https://hub.docker.com/r/apache/skywalking-oap-server
    # or https://github.com/apache/skywalking-docker/blob/master/6/6.4/oap/README.md#sw_telemetry
ui:
  name: skywalking-ui
  replicas: 1
  image:
    repository: apache/skywalking-ui
    tag: 6.4.0
    pullPolicy: IfNotPresent
  # podAnnotations:
  #   example: oap-foo
  ingress:
    enabled: false
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    path: /
    hosts: []
    # - skywalking.local
    tls: []
    #  - secretName: skywalking-tls
    #    hosts:
    #      - skywalking.local
  service:
    type: ClusterIP
    # clusterIP: None
    externalPort: 80
    internalPort: 8080
    ## External IP addresses of service
    ## Default: nil
    ##
    # externalIPs:
    # - 192.168.0.1
    #
    ## LoadBalancer IP if service.type is LoadBalancer
    ## Default: nil
    ##
    # loadBalancerIP: 10.2.2.2
    # Annotation example: setup ssl with aws cert when service.type is LoadBalancer
    # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:us-east-1:EXAMPLE_CERT
    annotations: {}
    ## Limit load balancer source ips to list of CIDRs (where available)
    # loadBalancerSourceRanges: []

elasticsearch:
  enabled: true
  # If elasticsearch,enabled=true values for elasticsearch.

  ## Define serviceAccount names for components. Defaults to component's fully qualified name.
  serviceAccounts:
    client:
      create: true
      name:
    master:
      create: true
      name:
    data:
      create: true
      name:

  client:
    name: client
    replicas: 2
    serviceType: ClusterIP
    ## If coupled with serviceType = "NodePort", this will set a specific nodePort to the client HTTP port
    # httpNodePort: 30920
    loadBalancerIP: {}
    loadBalancerSourceRanges: {}
    ## (dict) If specified, apply these annotations to the client service
    #  serviceAnnotations:
    #    example: client-svc-foo
    heapSize: "512m"
    # additionalJavaOpts: "-XX:MaxRAM=512m"
    antiAffinity: "soft"
    nodeAffinity: {}
    nodeSelector: {}
    tolerations: []
    initResources: {}
      # limits:
      #   cpu: "25m"
      #   # memory: "128Mi"
      # requests:
      #   cpu: "25m"
    #   memory: "128Mi"
    resources:
      limits:
        cpu: "1"
        # memory: "1024Mi"
      requests:
        cpu: "25m"
        memory: "512Mi"
    priorityClassName: ""
    ## (dict) If specified, apply these annotations to each client Pod
    # podAnnotations:
    #   example: client-foo
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
      # maxUnavailable: 1
    ingress:
      enabled: false
      # user: NAME
      # password: PASSWORD
      annotations: {}
        # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
      path: /
      hosts:
        - chart-example.local
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local

  master:
    name: master
    exposeHttp: false
    replicas: 3
    heapSize: "512m"
    # additionalJavaOpts: "-XX:MaxRAM=512m"
    persistence:
      enabled: false
      accessMode: ReadWriteOnce
      name: data
      size: "4Gi"
      # storageClass: "ssd"
    readinessProbe:
      httpGet:
        path: /_cluster/health?local=true
        port: 9200
      initialDelaySeconds: 5
    antiAffinity: "soft"
    nodeAffinity: {}
    nodeSelector: {}
    tolerations: []
    initResources: {}
      # limits:
      #   cpu: "25m"
      #   # memory: "128Mi"
      # requests:
      #   cpu: "25m"
    #   memory: "128Mi"
    resources:
      limits:
        cpu: "1"
        # memory: "1024Mi"
      requests:
        cpu: "25m"
        memory: "512Mi"
    priorityClassName: ""
    ## (dict) If specified, apply these annotations to each master Pod
    # podAnnotations:
    #   example: master-foo
    podManagementPolicy: OrderedReady
    podDisruptionBudget:
      enabled: false
      minAvailable: 2  # Same as `cluster.env.MINIMUM_MASTER_NODES`
      # maxUnavailable: 1
    updateStrategy:
      type: OnDelete

  data:
    name: data
    exposeHttp: false
    replicas: 2
    heapSize: "1536m"
    # additionalJavaOpts: "-XX:MaxRAM=1536m"
    persistence:
      enabled: false
      accessMode: ReadWriteOnce
      name: data
      size: "30Gi"
      # storageClass: "ssd"
    readinessProbe:
      httpGet:
        path: /_cluster/health?local=true
        port: 9200
      initialDelaySeconds: 5
    terminationGracePeriodSeconds: 3600
    antiAffinity: "soft"
    nodeAffinity: {}
    nodeSelector: {}
    tolerations: []
    initResources: {}
      # limits:
      #   cpu: "25m"
      #   # memory: "128Mi"
      # requests:
      #   cpu: "25m"
    #   memory: "128Mi"
    resources:
      limits:
        cpu: "1"
        # memory: "2048Mi"
      requests:
        cpu: "25m"
        memory: "1536Mi"
    priorityClassName: ""
    ## (dict) If specified, apply these annotations to each data Pod
    # podAnnotations:
    #   example: data-foo
    podDisruptionBudget:
      enabled: false
      # minAvailable: 1
      maxUnavailable: 1
    podManagementPolicy: OrderedReady
    updateStrategy:
      type: OnDelete
    hooks:  # post-start and pre-stop hooks
      drain:  # drain the node before stopping it and re-integrate it into the cluster after start
        enabled: true

nameOverride: ""
