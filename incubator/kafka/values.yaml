# ------------------------------------------------------------------------------
# Kafka:
# ------------------------------------------------------------------------------

## The StatefulSet installs 3 pods by default
replicas: 3

## The kafka image repository
image: "confluentinc/cp-kafka"

## The kafka image tag
imageTag: "4.0.1-1"

## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: "IfNotPresent"

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources: {}
  # limits:
  #   cpu: 200m
  #   memory: 1536Mi
  # requests:
  #   cpu: 100m
  #   memory: 1024Mi
kafkaHeapOptions: "-Xmx1G -Xms1G"

## The StatefulSet Update Strategy which Kafka will use when changes are applied.
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
updateStrategy:
  type: "OnDelete"

## Start and stop pods in Parallel or OrderedReady (one-by-one.)  Note - Can not change after first release.
## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy
podManagementPolicy: OrderedReady

## The name of the storage class which the cluster should use.
# storageClass: default

## The subpath within the Kafka container's PV where logs will be stored.
## This is combined with `persistence.mountPath`, to create, by default: /opt/kafka/data/logs
logSubPath: "logs"

## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

## Pod scheduling preferences.
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Node labels for pod assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
nodeSelector: {}

## Readiness probe config.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
##
readinessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

## Period to wait for broker graceful shutdown (sigterm) before pod is killed (sigkill)
## ref: https://kubernetes-v1-4.github.io/docs/user-guide/production-pods/#lifecycle-hooks-and-termination-notice
## ref: https://kafka.apache.org/10/documentation.html#brokerconfigs controlled.shutdown.*
terminationGracePeriodSeconds: 60

# Tolerations for nodes that have taints on them.
# Useful if you want to dedicate nodes to just run kafka
# https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
tolerations: []
# tolerations:
# - key: "key"
#   operator: "Equal"
#   value: "value"
#   effect: "NoSchedule"

## External access.
##
external:
  enabled: false
  servicePort: 19092
  firstListenerPort: 31090
  domain: cluster.local
  init:
    image: "lwolf/kubectl_deployer"
    imageTag: "0.4"
    imagePullPolicy: "IfNotPresent"

## Configuration Overrides. Specify any Kafka settings you would like set on the StatefulSet
## here in map format, as defined in the official docs.
## ref: https://kafka.apache.org/documentation/#brokerconfigs
##
configurationOverrides:
  "offsets.topic.replication.factor": 3
  # "auto.leader.rebalance.enable": true
  # "auto.create.topics.enable": true
  # "controlled.shutdown.enable": true
  # "controlled.shutdown.max.retries": 100

  ## Options required for external access via NodePort
  ## ref:
  ## - http://kafka.apache.org/documentation/#security_configbroker
  ## - https://cwiki.apache.org/confluence/display/KAFKA/KIP-103%3A+Separation+of+Internal+and+External+traffic
  ##
  ## Setting "advertised.listeners" here appends to "PLAINTEXT://${POD_IP}:9092,"
  # "advertised.listeners": |-
  #   EXTERNAL://kafka.cluster.local:$((31090 + ${KAFKA_BROKER_ID}))
  # "listener.security.protocol.map": |-
  #   PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT

## A collection of additional ports to expose on brokers (formatted as normal containerPort yaml)
# Useful when the image exposes metrics (like prometheus, etc.) through a javaagent instead of a sidecar
additionalPorts: {}

## Persistence configuration. Specify if and how to persist data to a persistent volume.
##
persistence:
  enabled: true

  ## The size of the PersistentVolume to allocate to each Kafka Pod in the StatefulSet. For
  ## production servers this number should likely be much larger.
  ##
  size: "1Gi"

  ## The location within the Kafka container where the PV will mount its storage and Kafka will
  ## store its logs.
  ##
  mountPath: "/opt/kafka/data"

  ## Kafka data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass:

## Metrics
##
metrics:

  jmx:
    enabled: false

    # The image to use for the metrics collector
    image: solsson/kafka-prometheus-jmx-exporter@sha256

    # The image tag to use for the metrics collector
    imageTag: a23062396cd5af1acdf76512632c20ea6be76885dfc20cd9ff40fb23846557e8

    # The port to expose JMX metrics on
    port: 5555

    # Rules to apply to the Kafka JMX Exporter
    kafkaConfig:
      lowercaseOutputName: true
      jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi
      ssl: false
      whitelistObjectNames: ["kafka.server:*", "kafka.controller:*", "java.lang:*"]
      # rules:
      #   - pattern : kafka.server<type=ReplicaFetcherManager, name=MaxLag, clientId=(.+)><>Value
      #   - pattern : kafka.server<type=BrokerTopicMetrics, name=(BytesInPerSec|BytesOutPerSec|MessagesInPerSec), topic=(.+)><>OneMinuteRate
      #   - pattern : kafka.server<type=KafkaRequestHandlerPool, name=RequestHandlerAvgIdlePercent><>OneMinuteRate
      #   - pattern : kafka.server<type=Produce><>queue-size
      #   - pattern : kafka.server<type=ReplicaManager, name=(PartitionCount|UnderReplicatedPartitions)><>(Value|OneMinuteRate)
      #   - pattern : kafka.server<type=controller-channel-metrics, broker-id=(.+)><>(.*)
      #   - pattern : kafka.server<type=socket-server-metrics, networkProcessor=(.+)><>(.*)
      #   - pattern : kafka.server<type=Fetch><>queue-size
      #   - pattern : kafka.server<type=SessionExpireListener, name=(.+)><>OneMinuteRate
      #   - pattern : kafka.controller<type=KafkaController, name=(.+)><>Value
      #   - pattern : java.lang<type=OperatingSystem><>SystemCpuLoad
      #   - pattern : java.lang<type=Memory><HeapMemoryUsage>used
      #   - pattern : java.lang<type=OperatingSystem><>FreePhysicalMemorySize

  kafka:
    enabled: false

    # The image to use for the metrics collector
    image: danielqsj/kafka-exporter

    # The image tag to use for the metrics collector
    imageTag: v1.0.1

# ------------------------------------------------------------------------------
# Zookeeper:
# ------------------------------------------------------------------------------

zookeeper:
  ## If true, install the Zookeeper chart alongside Kafka
  ## ref: https://github.com/kubernetes/charts/tree/master/incubator/zookeeper
  enabled: true

  ## Configure Zookeeper resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: ~

  ## The JVM heap size to allocate to Zookeeper
  heap: "1G"

  persistence:
    enabled: false
    ## The amount of PV storage allocated to each Zookeeper pod in the statefulset
    # storage: "2Gi"

  ## Specify a Zookeeper imagePullPolicy
  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
  imagePullPolicy: "IfNotPresent"

  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
  port: 2181
