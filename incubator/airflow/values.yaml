# Duplicate this file and put your customization here


##
## common settings and setting for the webserver
airflow:
  ##
  ## You will need to define your frenet key:
  ## Generate fernet_key with:
  ##    python -c "from cryptography.fernet import Fernet; FERNET_KEY = Fernet.generate_key().decode(); print(FERNET_KEY)"
  ## fernet_key: ABCDABCDABCDABCDABCDABCDABCDABCDABCDABCD
  fernet_key: ""
  service:
    type: ClusterIP
  ##
  ## set the max number of retries during container initialization
  init_retry_loop:
  ##
  ## base image for webserver/scheduler/workers
  ## Note: If you want to use airflow HEAD (2.0dev), use the following image:
  # image
  #   repository: stibbons31/docker-airflow-dev
  #   tag: 2.0dev
  ## Airflow 2.0 allows changing the value ingress.web.path and ingress.flower.path (see bellow).
  ## In version < 2.0, changing these paths won't have any effect.
  image:
    ##
    ## docker-airflow image
    repository: puckel/docker-airflow
    ##
    ## image tag
    tag: 1.9.0-4
    ##
    ## Image pull policy
    ## values: Always or IfNotPresent
    pull_policy: IfNotPresent
  ##
  ## Set scheduler_num_runs to control how the schduler behaves:
  ##   -1 will let him looping indefinitively but it will never update the DAG
  ##   1 will have the scheduler quit after each refresh, but kubernetes will restart it
  scheduler_num_runs: "-1"
  ##
  ## Set scheduler_do_pickle to toggle whether to have the scheduler
  ## attempt to pickle the DAG object to send over to the workers,
  ## instead of letting workers run their version of the code.
  ## See the Airflow documentation for the --do_pickle argument: https://airflow.apache.org/cli.html#scheduler
  scheduler_do_pickle: true
  ##
  ## how many replicas for web server
  ## For the moment, we recommend to leave this value to 1, since the webserver instance performs
  ## the 'initdb' operation, starting more replicas will cause all the web containers to execute
  ## it, which may cause unwanted issues on the database.
  web_replicas: 1
  ##
  ## Custom airflow configuration environment variables
  ## Use this to override any airflow setting settings defining environment variables in the
  ## following form: AIRFLOW__<section>__<key>.
  ## See the Airflow documentation: http://airflow.readthedocs.io/en/latest/configuration.html?highlight=__CORE__#setting-configuration-options)
  ## Example:
  ##   config:
  ##     AIRFLOW__CORE__EXPOSE_CONFIG: "True"
  ##     HTTP_PROXY: "http://proxy.mycompany.com:123"
  config: {}
  ##
  ## Configure pod disruption budget for the scheduler
  pod_disruption_budget:
    maxUnavailable: 1

##
## Workers configuration
workers:
  ##
  ## Service account name
  serviceAccountName: "default"
  ##
  ## Number of workers pod to launch
  replicas: 1
  ##
  ## Custom resource configuration
  resources: {}
    # limits:
    #   cpu: "1"
    #   memory: "2G"
    # requests:
    #   cpu: "0.5"
    #   memory: "512Mi"
  ##
  ## Celery worker configuration
  celery:
    ##
    ## number of parallel celery tasks per worker
    instances: 1


##
## Ingress configuration
ingress:
  ##
  ## enable ingress
  ## Note: If you want to change url prefix for web ui or flower even if you do not use ingress,
  ## you can still change ingress.web.path and ingress.flower.path
  enabled: false
  ##
  ## Configure the webserver endpoint
  web:
    ## NOTE: This requires an airflow version > 1.9.x
    ## For the moment (March 2018) this is **not** available on official package, you will have
    ## to use an image where airflow has been updated to its current HEAD.
    ## You can use the following one:
    ##  stibbons31/docker-airflow-dev:2.0dev
    ##
    ## if web is '/airflow':
    ##  - UI will be accessible at 'http://mycompany.com/airflow/admin'
    ##  - Healthcheck is at 'http://mycompany.com/airflow/health'
    ##  - api is at 'http://mycompany.com/airflow/api'
    ## NOTE: do NOT keep trailing slash. For root configuration, set and empty string
    path: ""
    ##
    ## hostname for the webserver
    host: ""
    ##
    ## Annotations for the webserver
    ## Airflow webserver handles relative path completely, just let your load balancer give the HTTP
    ## header like the requested URL (no special configuration neeed)
    annotations:
      ##
      ## Example for Traefik:
      # traefik.frontend.rule.type: PathPrefix
      # kubernetes.io/ingress.class: traefik
  ##
  ## Configure the flower endpoind
  flower:
    ##
    ## if flower is '/airflow/flower':
    ##  - Flower UI is at 'http://mycompany.com/airflow/flower'
    ## NOTE: you need to have a reverse proxy/load balancer able to do URL rewrite in order to have
    ## flower mounted on other path than root. Flower only does half the job in url prefixing: it
    ## only generates the right URL/relative paths in the **returned HTML files**, but expects the
    ## request to have been be at the root.
    ## That's why we need a reverse proxy/load balancer that is able to strip the path
    ## NOTE: do NOT keep trailing slash. For root configuration, set and empty string
    path: ""
    ##
    ## Configure the liveness path. Keep to "/" for Flower >= jan 2018.
    ## For previous version, enter the same path than in the 'path' key
    ## NOTE: keep the trailing slash.
    liveness_path: /
    ##
    ## hostname for flower
    host: ""
    ##
    ## Annotation for the Flower endpoint
    ##
    ## ==== SKIP THE FOLLOWING BLOCK IF YOU HAVE FLOWER > JANUARY 2018 =============================
    ## Please note their is a small difference between the way Airflow Web server and Flower handles
    ## URL prefixes in HTTP requests:
    ## Flower wants HTTP header to behave like there was no URL prefix, and but still generates
    ## the right URL in html pages thanks to its `--url-prefix` parameter
    ##
    ##    Extracted from the Flower documentation:
    ##    (https://github.com/mher/flower/blob/master/docs/config.rst#url_prefix)
    ##
    ##        To access Flower on http://example.com/flower run it with:
    ##            flower --url-prefix=/flower
    ##
    ##        Use the following nginx configuration:
    ##            server {
    ##              listen 80;
    ##              server_name example.com;
    ##
    ##              location /flower/ {
    ##                rewrite ^/flower/(.*)$ /$1 break;
    ##                proxy_pass http://example.com:5555;
    ##                proxy_set_header Host $host;
    ##              }
    ##            }
    ## ==== IF YOU HAVE FLOWER > JANUARY 2018, NO MORE NEED TO STRIP THE PREFIX ====================
    annotations:
      ##
      ## NOTE: it is important here to have your reverse proxy strip the path/rewrite the URL
      ## Example for Traefik:
      # traefik.frontend.rule.type: PathPrefix       ## Flower >= Jan 2018
      # traefik.frontend.rule.type: PathPrefixStrip  ## Flower < Jan 2018
      # kubernetes.io/ingress.class: traefik


##
## Storage configuration for DAGs
persistence:
  ##
  ## enable persistance storage
  enabled: false
  ##
  ## Existing claim to use
  existingclaim: nil
  ##
  ## Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  # storageClass: default
  accessMode: ReadWriteOnce
  ##
  ## Persistant storage size request
  size: 1Gi


##
## Configure DAGs deployment and update
dags:
  ##
  ## mount path for persistent volume.
  ## Note that this location is referred to in airflow.cfg, so if you change it, you must update airflow.cfg accordingly.
  path: /usr/local/airflow/dags
  git:
    ##
    ## url to clone the git repository
    url:
    ##
    ## branch name, tag or sha1 to reset to
    ref: master
  init_container:
    ## Fetch the source code when the pods starts
    enabled: false
    ## install requirements.txt dependencies automatically
    install_requirements: true

##
## Configuration values for the postgresql dependency.
## ref: https://github.com/kubernetes/charts/blob/master/stable/postgresql/README.md
postgresql:
  ##
  ## Use the PostgreSQL chart dependency.
  ## Set to false if bringing your own PostgreSQL.
  enabled: true
  ##
  ## If bringing your own PostgreSQL, the full uri to use
  ## e.g. postgres://airflow:changeme@my-postgres.com:5432/airflow?sslmode=disable
  # uri:
  ##
  ### PostgreSQL User to create.
  postgresUser: postgres
  ##
  ## PostgreSQL Password for the new user.
  ## If not set, a random 10 characters password will be used.
  postgresPassword: airflow
  ##
  ## PostgreSQL Database to create.
  postgresDatabase: airflow
  ##
  ## Persistent Volume Storage configuration.
  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes
  persistence:
    ##
    ## Enable PostgreSQL persistence using Persistent Volume Claims.
    enabled: true
    ##
    ## Persistant class
    # storageClass: classname
    ##
    ## Access mode:
    accessMode: ReadWriteOnce


## Configuration values for the Redis dependency.
## ref: https://github.com/kubernetes/charts/blob/master/stable/redis/README.md
redis:
  ##
  ## Use the redis chart dependency.
  ## Set to false if bringing your own redis.
  enabled: true
  ##
  ## Redis password
  password: airflow
  ##
  ## Master configuration
  master:
    ##
    ## Image configuration
    # image:
      ##
      ## docker registry secret names (list)
      # pullSecrets: nil
    ##
    ## Configure persistance
    persistence:
      ##
      ## Use a PVC to persist data.
      enabled: false
      ##
      ## Persistant class
      # storageClass: classname
      ##
      ## Access mode:
      accessMode: ReadWriteOnce
  ##
  ## Disable cluster management by default.
  cluster:
    enabled: false
