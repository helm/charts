###
# #%L
# thinkbig-service-app
# %%
# Copyright (C) 2017 ThinkBig Analytics
# %%
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# #L%
###
###
# Other properties are in the services-app/application.properties
#
# Add extra profiles by setting "spring.profiles.active=<profile-name>" property on command line, e.g.
# -Dspring.profiles.active=hdp24,gmail,cdh
# Extra profiles will add to this set of profiles and override properties given in this file
### Indicate the NiFi version you are using with the correct spring profile.
###  - For NiFi 1.0.x:                      nifi-v1
###  - For NiFi 1.1.x:                      nifi-v1.1
###  - For NiFi 1.2.x or 1.3.x or 1.4.x:    nifi-v1.2
{{- if .Values.kylo.activeDirectory.enabled }}
spring.profiles.include=native,nifi-v1.2,auth-spark,auth-kylo,auth-ldap,search-esr,jms-activemq
{{ else }}
spring.profiles.include=native,nifi-v1.2,auth-spark,auth-kylo,auth-file,search-esr,jms-activemq
{{ end }}
# Spring Datasource properties for spring batch and the default data source
# NOTE: Cloudera default password for root access to mysql is "cloudera"
#
spring.datasource.url=jdbc:mysql://{{ template "kylo.fullname" . }}-mysql:3306/kylo
spring.datasource.username=root
spring.datasource.password=hadoop
spring.datasource.maxActive=30
spring.datasource.validationQuery=SELECT 1
spring.datasource.testOnBorrow=true
spring.datasource.driverClassName=org.mariadb.jdbc.Driver
spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect
spring.jpa.open-in-view=true
#
#Postgres datasource configuration
#
#spring.datasource.url=jdbc:postgresql://localhost:5432/pipeline_db
#spring.datasource.driverClassName=org.postgresql.Driver
#spring.datasource.username=root
#spring.datasource.password=thinkbig
#spring.jpa.database-platform=org.hibernate.dialect.PostgreSQLDialect
# Entity-level access control. To enable, uncomment below line and set value as true.
# WARNING: Enabling entity access control is a one-way operation; you will not be able
# to set this poperty back to "false" once Kylo is started with this value as "true".
#security.entity.access.controlled=false
###
# Authentication settings:
#
# Currently available athentication/authorization Spring profiles:
#   *  auth-kylo   - Users are authenticated if they exist in the Kylo user store and any
#                    groups associated with the user are retrieved for access control.
#                    This profile is usually used in conjuction with other auth profiles
#                    (auth-ldap, auth-ad, etc.)
#   *  auth-ldap   - authenticates users using LDAP and optionally loads any associated
#                    user groups
#   *  auth-ad     - authenticates users using Active Directory and loads any associated
#                    user groups
#   *  auth-simple - Uses authenticationService.username and authenticationService.password
#                    for authentication (development only)
#   *  auth-file   - Uses users.properties and roles.properties files for authentication
#                    and role assignment (generally for development only)
## auth-file: If this profile is active then these optional properties may be used:
security.auth.file.users=file:///opt/kylo/kylo-services/conf/users.properties
security.auth.file.groups=file:///opt/kylo/kylo-services/conf/groups.properties
security.auth.file.password.hash.enabled=false
security.auth.file.password.hash.algorithm=MD5
security.auth.file.password.hash.encoding=base64
## auth-simple: If this profile is active these authenticationService properties are used:
#authenticationService.username=
#authenticationService.password={cipher}
#authenticationService.password=
{{- if .Values.kylo.activeDirectory.enabled }}
## auth-ldap: If this profile is active then these properties should uncommented and updated appropriately
security.auth.ldap.server.uri=ldap://idm.daf.gov.it:389/cn=users,cn=accounts,dc=daf,dc=gov,dc=it
security.auth.ldap.server.authDn=uid=admin,cn=users,cn=accounts,dc=daf,dc=gov,dc=it
security.auth.ldap.server.password=xxxxx
### user DN patterns are separated by '|'
security.auth.ldap.authenticator.userDnPatterns=uid={0}
security.auth.ldap.authenticator.userDnPatterns=uid={0},ou=people
security.auth.ldap.user.enableGroups=true
security.auth.ldap.user.groupNameAttr=cn
security.auth.ldap.user.groupsBase=cn=groups,cn=accounts
{{ end }}
## auth-ad: If this profile is active then these properties should uncommented and updated appropriately
#security.auth.ad.server.uri=ldap://idm.daf.gov.it
#security.auth.ad.server.domain=cn=users,cn=accounts,dc=daf,dc=gov,dc=it
#security.auth.ad.server.searchFilter=(&(objectClass=user)(sAMAccountName={1}))
#security.auth.ad.user.enableGroups=true
## group attribute patterns are separated by '|'
#security.auth.ad.user.groupAttributes=
#
# Server port
#
server.port=8420
# server.port=8443
##### ADD IF SSL is needed
###
#server.ssl.key-store=
#server.ssl.key-store-password=
#server.ssl.key-store-type=jks
#server.ssl.trust-store=
#server.ssl.trust-store-password=
#server.ssl.trust-store-type=JKS
#
# General configuration - Note: Supported configurations include STANDALONE, BUFFER_NODE_ONLY, BUFFER_NODE, EDGE_NODE
#
application.mode=STANDALONE
#
# Turn on debug mode to display more verbose error messages in the UI
#
application.debug=true
#
# Prevents execution of jobs at startup.  Change to true, and the name of the job that should
# be run at startup if we want that behavior
#
spring.batch.job.enabled=false
spring.batch.job.names=
#spring.jpa.show-sql=true
#spring.jpa.hibernate.ddl-auto=validate
metadata.datasource.driverClassName=${spring.datasource.driverClassName}
metadata.datasource.url=${spring.datasource.url}
metadata.datasource.username=${spring.datasource.username}
metadata.datasource.password=${spring.datasource.password}
metadata.datasource.validationQuery=SELECT 1
metadata.datasource.testOnBorrow=true
hive.userImpersonation.enabled=false
hive.datasource.driverClassName=org.apache.hive.jdbc.HiveDriver
hive.datasource.url=jdbc:hive2://master.platform.daf.gov.it:10000/default;principal=hive/master.platform.daf.gov.it@DAF.GOV.IT
hive.datasource.username=daf
hive.datasource.password=xxxxxx
hive.datasource.validationQuery=show tables
##Also Clouder  url should be /metastore instead of /hive
hive.metastore.datasource.driverClassName=org.postgresql.Driver
hive.metastore.datasource.url=jdbc:postgresql://master/metastore
#hive.metastore.datasource.url=jdbc:mysql://localhost:3306/metastore
hive.metastore.datasource.username=hive
hive.metastore.datasource.password=xxxxxx
hive.metastore.datasource.validationQuery=SELECT 1
hive.metastore.datasource.testOnBorrow=true
modeshape.datasource.driverClassName=${spring.datasource.driverClassName}
modeshape.datasource.url=${spring.datasource.url}
modeshape.datasource.username=${spring.datasource.username}
modeshape.datasource.password=${spring.datasource.password}
modeshape.index.dir=/opt/kylo/modeshape/modeshape-local-index
nifi.rest.host={{ template "kylo.fullname" . }}-nifi
nifi.rest.port=8080
###
# NiFi Https configuration below
#
# Follow directions here: http://kylo.readthedocs.io/en/v0.8.2/how-to-guides/ConfigureNiFiWithSSL.html to setup certificates and properties in NiFi
#
### The port should match the port found in the /opt/nifi/current/conf/nifi.properties (nifi.web.https.port)
#nifi.rest.port=9443
#nifi.rest.https=true
#nifi.rest.useConnectionPooling=false
#nifi.rest.truststorePath=
#####the truststore password below needs to match that found in the nifi.properties file (nifi.security.truststorePasswd)
#nifi.rest.truststorePassword=
#nifi.rest.truststoreType=JKS
#nifi.rest.keystorePath=
###value found in the .password file /opt/nifi/data/ssl/CN=kylo_OU=NIFI.password
#nifi.rest.keystorePassword=
#nifi.rest.keystoreType=PKCS12
#
kerberos.hive.kerberosEnabled=false
kerberos.hive.hadoopConfigurationResources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
kerberos.hive.kerberosPrincipal=daf@DAF.GOV.IT
kerberos.hive.keytabLocation=/etc/security/daf.keytab
## used to map Nifi Controller Service connections to the User Interface
## naming convention for the property is nifi.service.NIFI_CONTROLLER_SERVICE_NAME.NIFI_PROPERTY_NAME
##anything prefixed with nifi.service  will be used by the UI.  Replace Spaces with underscores and make it lowercase.
nifi.service.mysql.database_user=root
nifi.service.mysql.password=hadoop
#Kylo MySQL controller service configuration
nifi.service.kylo_mysql.database_user=root
nifi.service.kylo_mysql.password=hadoop
nifi.service.hive_thrift_service.database_connection_url=jdbc:hive2://master.platform.daf.gov.it:10000/default;principal=hive/master.platform.daf.gov.it@DAF.GOV.IT
nifi.service.hive_thrift_service.kerberos_principal=nifi
nifi.service.hive_thrift_service.kerberos_keytab=/opt/nifi/daf.keytab
nifi.service.hive_thrift_service.hadoop_configuration_resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
nifi.service.kylo_metadata_service.rest_client_url=http://{{ template "kylo.fullname" . }}-kylo-ui:8400/proxy/v1/metadata
nifi.service.kylo_metadata_service.rest_client_password=thinkbig
jms.client.id=thinkbig.feedmgr
## nifi Property override with static defaults
##Static property override supports 3 usecases
# 1) store properties in the file starting with the prefix defined in the "PropertyExpressionResolver class"  default = config.
# 2) store properties in the file starting with "nifi.<PROCESSORTYPE>.<PROPERTY_KEY>   where PROCESSORTYPE and PROPERTY_KEY are all lowercase and the spaces are substituted with underscore
# 3) Global property replacement.  properties starting with "nifi.all_processors.<PROPERTY_KEY> will globally replace the value when the template is instantiated
##Below are Ambari configuration options for Hive Metastore and Spark location
config.hive.schema=hive
config.metadata.url=http://kylo-ui:8400/proxy/v1/metadata
## Spark configuration
nifi.executesparkjob.sparkhome=/opt/cloudera/parcels/SPARK2/lib/spark2
nifi.executesparkjob.sparkmaster=yarn
nifi.executesparkjob.driver_memory=1024m
nifi.executesparkjob.number_of_executors=1
nifi.executesparkjob.executor_cores=1
##comment the line below on cloudera
#config.spark.validateAndSplitRecords.extraJars=/usr/hdp/current/hive-webhcat/share/hcatalog/hive-hcatalog-core.jar
config.spark.version=2
## Specify to override the default HDFS locations for feed tables and multi-tenancy.
# Root HDFS locations for new raw files
config.hdfs.ingest.root=/app/tba/etl
# Root Archive location for new raw files
config.hdfs.archive.root=/app/tba/archive
# Root HDFS location for Hive ingest processing tables (raw,valid,invalid)
config.hive.ingest.root=/app/tba/model.db
# Root HDFS location for Hive profile table
config.hive.profile.root=/app/tba/model.db
# Root HDFS location for Hive master table
config.hive.master.root=/daf
# Prefix to prepend to category system name for this environment (blank if none). Use for multi-tenancy
config.category.system.prefix=
# Set the JMS server hostname for the Kylo hosted JMS server
config.elasticsearch.jms.url=tcp://{{ template "kylo.fullname" . }}-activemq:61616
# Set the nifi home folder
config.nifi.home=/opt/nifi
#example of replacing global properties
nifi.all_processors.kerberos_principal=daf@DAF.GOV.IT
nifi.all_processors.kerberos_keytab=/opt/nifi/daf.keytab
nifi.all_processors.hadoop_configuration_resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
##cloudera config
#config.hive.schema=metastore
#nifi.executesparkjob.sparkhome=/usr/lib/spark
## how often should SLAs be checked
sla.cron.default=0 0/5 * 1/1 * ? *
# Additional Hive UDFs for partition functions. Separate multiple functions with commas.
#kylo.metadata.udfs=
### Sqoop import configuration
# DB Connection password and driver (format: nifi.service.<sqoop controller service name in NiFi>.<key>=<value>
# Note: Ensure that the driver jar is available in below two locations:
# (a) sqoop's lib directory (e.g. /usr/hdp/current/sqoop-client/lib/)
# (b) kylo's lib directory, and owned by 'kylo' user (/opt/kylo/kylo-services/lib)
#nifi.service.sqoop-mysql-connection.password=hadoop
#nifi.service.sqoop-mysql-connection.database_driver_class_name=com.mysql.jdbc.Driver
# Base HDFS landing directory
#config.sqoop.hdfs.ingest.root=/sqoopimport
##uncommenet the settings below for Gmail to work
#sla.mail.protocol=smtp
#sla.mail.host=smtp.google.com
#sla.mail.port=587
#sla.mail.smtpAuth=true
#sla.mail.starttls=true
# Login form authentication
#security.jwt.algorithm=HS256
security.jwt.key=<insert-256-bit-secret-key-here>
#security.rememberme.alwaysRemember=false
#security.rememberme.cookieDomain=localhost
#security.rememberme.cookieName=remember-me
#security.rememberme.parameter=remember-me
#security.rememberme.tokenValiditySeconds=1209600
#security.rememberme.useSecureCookie=
## if a job fails tell operations manager to query nifi for bulletin information in an attempt to capture more logs about the failure
kylo.ops.mgr.query.nifi.bulletins=true
##when getting aggregate stats back for flows if errors are detected kylo will query NiFi in attempt to capture matching bulletins.
## by default this data is stored in memory.  Setting this to true will store the data in the MySQL table
kylo.ops.mgr.stats.nifi.bulletins.persist=false
## if not perisiting (above flag is false) this is the limit to the number of error bulletins per feed.
## this is a rolling queue that will keep the last # of errors per feed
kylo.ops.mgr.stats.nifi.bulletins.mem.size=30
kylo.feed.mgr.cleanup.timeout=60000
## Align the process groups when saving you feed in NiFi.  By default it is set to true.
#nifi.auto.align=false
# update database on kylo-services start
liquibase.enabled=true
liquibase.change-log=classpath:com/thinkbiganalytics/db/master.xml
# NiFi settings
nifi.service.kylo_mysql.database_connection_url=jdbc:mariadb://{{ template "kylo.fullname" . }}-mysql:3306
nifi.service.kylo_mysql.database_driver_class_name=org.mariadb.jdbc.Driver
nifi.service.kylo_mysql.database-driver-locations=file:///opt/nifi/drivers/mariadb-java-client-2.2.4.jar
nifi.service.kylo_mysql.database_user=root
nifi.service.kylo_mysql.password=hadoop
nifi.service.kylo_metadata_service.rest_client_user_name=dladmin
nifi.service.jmsconnectionfactoryprovider.mq_client_libraries_path_(i.e.,_/usr/jms/lib)=/opt/nifi/activemq
nifi.service.jmsconnectionfactoryprovider.broker_uri=tcp://{{ template "kylo.fullname" . }}-activemq:61616
nifi.service.hive_thrift_service.database_user=root
nifi.service.hive_thrift_service.password=hadoop
nifi.executesparkjob[validate_and_split_records].extra_jars=/opt/nifi/drivers/mariadb-java-client-2.2.4.jar
nifi.executesparkjob[profile_data].extra_jars=/opt/nifi/drivers/mariadb-java-client-2.2.4.jar
nifi.executesparkjob[validate_and_split_records].spark_configurations=spark.default.parallelism=4
nifi.executesparkjob[profile_data].spark_configurations=spark.default.parallelism=4
jms.activemq.broker.url=tcp://{{ template "kylo.fullname" . }}-activemq:61616
