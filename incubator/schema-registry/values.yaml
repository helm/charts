# Default values for Confluent Schema-Registry
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.
# name: value


## schema-registry repository
image: "confluentinc/cp-schema-registry"
## The container tag to use
imageTag: 4.0.1
## Specify a imagePullPolicy
## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
imagePullPolicy: "IfNotPresent"

## Number of Schema Registry Pods to Deploy
replicaCount: 1

## Schema Registry Settings Overrides
## Configuration Options can be found here: https://docs.confluent.io/current/schema-registry/docs/config.html
configurationOverrides:
  kafkastore.topic.replication.factor: 1

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
## Confluent has production deployment guidelines here:
## ref: https://github.com/confluentinc/schema-registry/blob/master/docs/deployment.rst
##
resources: {}
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

## The port on which the SchemaRegistry will be available and serving requests
servicePort: 8081

## If `Kafka.Enabled` is `false`, kafkaStore.overrideBootstrapServers must be provided for Master Election.
## You can list load balanced service endpoint, or list of all brokers (which is hard in K8s).  e.g.:
## overrideBootstrapServers: "PLAINTEXT://dozing-prawn-kafka-headless:9092"
## Charts uses Kafka Coordinator Master Election: https://docs.confluent.io/current/schema-registry/docs/design.html#kafka-coordinator-master-election
kafkaStore:
  overrideBootstrapServers: ""
  # By Default uses Release Name, but can be overridden.  Which means each release is its own group of
  # Schema Registry workers.  You can have multiple groups talking to same Kafka Cluster
  overrideGroupId: ""
  ## Additional Java arguments to pass to Kafka.
  # schemaRegistryOpts: -Dfoo=bar

## Readiness probe config.
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/
##
readinessProbe:
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

# Options for connecting to SASL kafka brokers
sasl:
  configPath: "/etc/kafka-config"
  scram:
    enabled: false
    init:
      image: "confluentinc/cp-schema-registry"
      imageTag: "4.0.0"
      imagePullPolicy: "IfNotPresent"
    clientUser: "kafka-client"
    zookeeperClientUser: "zookeeper-client"
    # Passwords can be either provided here or pulled from an existing k8s secret.
    # If user wants to specify the password here:
    clientPassword: "client-password"
    zookeeperClientPassword: "zookeeper-client-password"
    # If user has an existing k8s secret they would like to use instead of generating them:
    # useExistingSecret:
    #   # Where to find the schema registry user secret
    #   clientPassword:
    #     secretKeyRef:
    #       name: "schema-reg-secret"
    #       key: "client-password"
    #   # Where to find the zookeeper user secret
    #   zookeeperClientPassword:
    #     secretKeyRef:
    #       name: "zookeeper-secret"
    #       key: "zokeeper-client-password"

## Kafka Settings
kafka:
  ## This is enabled only to allow installations of this chart without arguments
  enabled: true
  imageTag: 4.0.1
  configurationOverrides:
    # Needed to run with 1 Kafka Broker
    offsets.topic.replication.factor: 1
  replicas: 1

  ## Install only a single Zookeeper pod in the StatefulSet
  zookeeper:
    servers: 1

ingress:
  enabled: false
  annotations: {}
  hostname: ""
  labels: {}
