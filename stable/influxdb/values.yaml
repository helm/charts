## influxdb image version
## ref: https://hub.docker.com/r/library/influxdb/tags/
image:
  repository: "influxdb"
  tag: "1.7.9-alpine"
  pullPolicy: IfNotPresent
  ## If specified, use these secrets to access the images
  # pullSecrets:
  #   - registry-secret


serviceAccount:
  create: true
  name:
  annotations: {}

## Customize liveness, readiness and startup probes
## ref: https://docs.influxdata.com/influxdb/v1.7/tools/api/#ping-http-endpoint
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
livenessProbe: {}
  # initialDelaySeconds: 30
  # timeoutSeconds: 5

readinessProbe: {}
  # initialDelaySeconds: 5
  # timeoutSeconds: 1

startupProbe:
  enabled: false
  # failureThreshold: 6
  # periodSeconds: 5

## Specify a service type
## NodePort is default
## ref: http://kubernetes.io/docs/user-guide/services/
##
service:
  ## Add annotations to service
  # annotations: {}
  type: ClusterIP

## Persist data to a persistent volume
##
persistence:
  enabled: true
  ## influxdb data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  annotations:
  accessMode: ReadWriteOnce
  size: 8Gi

## Deploy InfluxDB Enterprise - License required
## ref: https://www.influxdata.com/products/influxdb-enterprise/
enterprise:
  enabled: false
  licensekey: {}
  clusterSize: 4
  meta:
    image:
      ## This image contains the enterprise meta node package for clustering.
      ## It is meant to be used in conjunction with the influxdb:data package of the same version.
      ## ref: https://hub.docker.com/_/influxdb
      tag: meta
    clusterSize: 3
    ## seed is hashed and used as `internal-shared-secret` for Meta service.
    seed: dead-beef-cafe-bae
    ## Configure resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    resources: {}
  #  resources:
  #    requests:
  #      memory: 512Mi
  #      cpu: 2
  #    limits:
  #      memory: 1Gi
  #      cpu: 4

## Create default user through Kubernetes job
## Defaults indicated below
##
setDefaultUser:
  enabled: false

  ## Image of the container used for job
  ## Default: appropriate/curl:latest
  ##
  image: appropriate/curl:latest

  ## Deadline for job so it does not retry forever.
  ## Default: activeDeadline: 300
  ##
  activeDeadline: 300

  ## Specify the number of retries before considering job as failed.
  ## https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#pod-backoff-failure-policy
  ##
  backoffLimit: 6

  ## Hook delete policy for helm.
  ## Default: hookDeletePolicy: hook-succeeded
  ##
  hookDeletePolicy: hook-succeeded

  ## Restart policy for job
  ## Default: OnFailure
  restartPolicy: OnFailure

  user:

    ## The user name
    ## Default: "admin"
    username: "admin"

    ## User password
    ## single quotes must be escaped (\')
    ## Default: (Randomly generated 10 characters of AlphaNum)
    # password:

    ## The user name and password are obtained from an existing secret. The expected
    ## keys are `influxdb-user` and `influxdb-password`.
    ## If set, the username and password values above are ignored.
    # existingSecret: influxdb-auth

    ## User privileges
    ## Default: "WITH ALL PRIVILEGES"
    privileges: "WITH ALL PRIVILEGES"

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
resources: {}
#  requests:
#    memory: 256Mi
#    cpu: 0.1
#  limits:
#    memory: 16Gi
#    cpu: 8

# Annotations to be added to InfluxDB pods
podAnnotations: {}

ingress:
  enabled: false
  tls: false
  # secretName: my-tls-cert # only needed if tls above is true
  hostname: influxdb.foobar.com
  annotations:
    # kubernetes.io/ingress.class: "nginx"
    # kubernetes.io/tls-acme: "true"

## Use an alternate scheduler, e.g. "stork".
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
# schedulerName:

## Node labels for pod assignment
## Ref: https://kubernetes.io/docs/user-guide/node-selection/
##
nodeSelector: {}

## Affinity for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Tolerations for pod assignment
## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []
# - key: "key"
#   operator: "Equal|Exists"
#   value: "value"
#   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

## The InfluxDB image uses several environment variables to automatically
## configure certain parts of the server.
## Ref: https://hub.docker.com/_/influxdb/
env: {}
  # - name: INFLUXDB_DB
  #   value: "demo"

## InfluxDB configuration
## ref: https://docs.influxdata.com/influxdb/v1.7/administration/config
config:
  reporting_disabled: false
  rpc: {}
  meta: {}
  data: {}
  coordinator: {}
  retention: {}
  shard_precreation: {}
  monitor: {}
  http: {}
  logging: {}
  subscriber: {}
  graphite: {}
  collectd: {}
  opentsdb: {}
  udp: {}
  continuous_queries: {}
  tls: {}

# Allow executing custom init scripts
#
# If the container finds any files with the extensions .sh or .iql inside of the
# /docker-entrypoint-initdb.d folder, it will execute them. The order they are
# executed in is determined by the shell. This is usually alphabetical order.
initScripts:
  enabled: false
  scripts:
    init.iql: |+
      CREATE DATABASE "telegraf" WITH DURATION 30d REPLICATION 1 NAME "rp_30d"

backup:
  enabled: false
  schedule: "0 0 * * *"
  annotations: {}

  ## Google Cloud Storage
  # gcs:
  #    serviceAccountSecret: influxdb-backup-key
  #    serviceAccountSecretKey: key.json
  #    destination: gs://bucket/influxdb

  ## Azure
  ## Secret is expected to have connection string stored in `connection-string` field
  ## Existing container will be used or private one withing storage account will be created.
  # azure:
  #   storageAccountSecret: influxdb-backup-azure-key
  #   destination_container: influxdb-container
  #   destination_path: ""
