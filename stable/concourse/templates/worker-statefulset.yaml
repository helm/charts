apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: {{ template "concourse.worker.fullname" . }}
  labels:
    app: {{ template "concourse.worker.fullname" . }}
    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
    release: "{{ .Release.Name }}"
    heritage: "{{ .Release.Service }}"

spec:
  serviceName: {{ template "concourse.worker.fullname" . }}
  replicas: {{ .Values.worker.replicas }}
  template:
    metadata:
      labels:
        app: {{ template "concourse.worker.fullname" . }}
      annotations:
        {{- range $key, $value := .Values.worker.annotations }}
        {{ $key }}: {{ $value | quote }}
        {{- end }}
    spec:
      serviceAccountName: {{ if .Values.rbac.create }}{{ template "concourse.worker.fullname" . }}{{ else }}{{ .Values.rbac.serviceAccountName }}{{ end }}
      tolerations:
{{ toYaml .Values.worker.tolerations | indent 8 }}
      terminationGracePeriodSeconds: {{ .Values.worker.terminationGracePeriodSeconds }}
      containers:
        - name: {{ template "concourse.worker.fullname" . }}
          image: "{{ .Values.image }}:{{ .Values.imageTag }}"
          imagePullPolicy: {{ default "" .Values.imagePullPolicy | quote }}
          command:
            - /bin/sh
          args:
            - -c
            - |-
              cp /dev/null /concourse-work-dir/.liveness_probe
              rm -rf /concourse-work-dir/*
              while ! concourse retire-worker --name=${HOSTNAME} | grep -q worker-not-found; do
                touch /concourse-work-dir/.pre_start_cleanup
                sleep 5
              done
              rm -f /concourse-work-dir/.pre_start_cleanup
              concourse worker --name=${HOSTNAME} | tee -a /concourse-work-dir/.liveness_probe
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - |-
                  FATAL_ERRORS=$( echo "${LIVENESS_PROBE_FATAL_ERRORS}" | grep -q '\S' && \
                      grep -F "${LIVENESS_PROBE_FATAL_ERRORS}" /concourse-work-dir/.liveness_probe )
                  cp /dev/null /concourse-work-dir/.liveness_probe
                  if [ ! -z "${FATAL_ERRORS}" ]; then
                    >&2 echo "Fatal error detected: ${FATAL_ERRORS}"
                    exit 1
                  fi
                  if [ -f /concourse-work-dir/.pre_start_cleanup ]; then
                    >&2 echo "Still trying to clean up before starting concourse. 'fly prune-worker -w ${HOSTNAME}' might need to be called to force cleanup."
                    exit 1
                  fi
            failureThreshold: 1
            initialDelaySeconds: 10
            periodSeconds: 10
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |-
                    while ! concourse retire-worker --name=${HOSTNAME} | grep -q worker-not-found; do
                      sleep 5
                    done
          env:
            - name: CONCOURSE_TSA_HOST
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: concourse-tsa-host
            - name: CONCOURSE_TSA_PORT
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: concourse-tsa-port
            - name: CONCOURSE_GARDEN_DOCKER_REGISTRY
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: garden-docker-registry
            - name: CONCOURSE_GARDEN_INSECURE_DOCKER_REGISTRY
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: garden-insecure-docker-registry
            - name: CONCOURSE_TSA_PUBLIC_KEY
              value: "/concourse-keys/host_key.pub"
            - name: CONCOURSE_TSA_WORKER_PRIVATE_KEY
              value: "/concourse-keys/worker_key"
            - name: CONCOURSE_WORK_DIR
              value: "/concourse-work-dir"
            - name: CONCOURSE_BAGGAGECLAIM_DRIVER
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: concourse-baggageclaim-driver
            - name: LIVENESS_PROBE_FATAL_ERRORS
              valueFrom:
                configMapKeyRef:
                  name: {{ template "concourse.concourse.fullname" . }}
                  key: worker-fatal-errors
{{- if .Values.worker.env }}
{{ toYaml .Values.worker.env | indent 12 }}
{{- end }}
          resources:
{{ toYaml .Values.worker.resources | indent 12 }}
          securityContext:
            privileged: true
          volumeMounts:
            - name: concourse-keys
              mountPath: /concourse-keys
              readOnly: true
            - name: concourse-work-dir
              mountPath: /concourse-work-dir
      affinity:
{{- if .Values.worker.additionalAffinities }}
{{ toYaml .Values.worker.additionalAffinities | indent 8 }}
{{- end }}
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: {{ template "concourse.worker.fullname" . }}
                  release: {{ .Release.Name | quote }}
      volumes:
        - name: concourse-keys
          secret:
            secretName: {{ template "concourse.concourse.fullname" . }}
            defaultMode: 0400
            items:
              - key: host-key-pub
                path: host_key.pub
              - key: worker-key
                path: worker_key
              - key: worker-key-pub
                path: worker_key.pub
  {{- if .Values.persistence.enabled }}
  volumeClaimTemplates:
    - metadata:
        name: concourse-work-dir
      spec:
        accessModes:
          - {{ .Values.persistence.worker.accessMode | quote }}
        resources:
          requests:
            storage: {{ .Values.persistence.worker.size | quote }}
      {{- if .Values.persistence.worker.storageClass }}
      {{- if (eq "-" .Values.persistence.worker.storageClass) }}
        storageClassName: ""
      {{- else }}
        storageClassName: "{{ .Values.persistence.worker.storageClass }}"
      {{- end }}
      {{- end }}
  {{- else }}
        - name: concourse-work-dir
          emptyDir: {}
  {{- end }}
{{- if and (eq .Capabilities.KubeVersion.Major "1") (ge .Capabilities.KubeVersion.Minor "7") }}
  updateStrategy:
    type: {{ .Values.worker.updateStrategy }}
{{- end }}
  podManagementPolicy: {{ .Values.worker.podManagementPolicy }}
