{{- $gpuCount := .Values.gpuCount -}}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ template "tensorflow-serving.fullname" . }}
  labels:
    heritage: {{ .Release.Service | quote }}
    release: {{ .Release.Name | quote }}
    chart: {{ template "tensorflow-serving.chart" . }}
    app: {{ template "tensorflow-serving.name" . }}
spec:
  replicas: {{ .Values.replicas }}
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      release: {{ .Release.Name | quote }}
      app: {{ template "tensorflow-serving.name" . }} 
  template:
    metadata:
      labels:
        heritage: {{ .Release.Service | quote }}
        release: {{ .Release.Name | quote }}
        chart: {{ template "tensorflow-serving.chart" . }}
        app: {{ template "tensorflow-serving.name" . }}
    spec:
      containers:
        - name: serving
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          imagePullPolicy: "{{ .Values.image.pullPolicy }}"
          command:
            - "/usr/bin/tensorflow_model_server"
          args:
            - "--port=9090"
            - "--model_name={{ .Values.modelName }}"
            - "--model_base_path={{ .Values.modelBasePath }}"
          ports:
            - containerPort: 9090
              name: serving
              protocol: TCP
          readinessProbe:
            tcpSocket:
              port: serving
            initialDelaySeconds: 15
            timeoutSeconds: 1
          resources:
{{ toYaml .Values.resources | indent 12 }}
          volumeMounts:
          {{- if .Values.mountPath }}
            - mountPath: {{ .Values.mountPath }}
          {{- else }}
            - mountPath: /data
          {{- end }}
              name: model-volume
      volumes:
        - name: model-volume
      {{- if .Values.persistence.enabled }}
          persistentVolumeClaim:
              claimName: {{ .Values.persistence.existingClaim | default (include "tensorflow-serving.fullname" .) }}
      {{- else }}
          emptyDir: {}
      {{- end }}
