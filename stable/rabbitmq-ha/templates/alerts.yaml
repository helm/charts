{{ if and .Values.prometheus.operator.alerts.enabled .Values.prometheus.operator.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-rabbitmq-alerts
  namespace: monitoring
  labels:
    app: "rabbitmq"
    chart: {{ .Chart.Name }}-{{ .Chart.Version }}
    heritage: {{ .Release.Service }}
    release: {{ .Release.Name }}
{{- if .Values.prometheus.operator.serviceMonitor.selector }}
{{ toYaml .Values.prometheus.operator.serviceMonitor.selector | indent 4 }}
{{- end }}
{{- if .Values.prometheus.operator.alerts.selector }}
{{ toYaml .Values.prometheus.operator.alerts.selector | indent 4 }}
{{- end }}
data:
  rabbitmq.rules: |-
    groups:
    - name: rabbitmq-alerts
      rules:
      - alert: RabbitMqClusterNodeDown
        expr: rabbitmq_up == 0
        for: 5m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} is down
          summary: RabbitMQ Node Is Down
      - alert: RabbitMqDiskSpaceAlarm
        expr: rabbitmq_node_disk_free_alarm == 1
        for: 1m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} Disk Space Alarm is going off.  Which means the node hit highwater mark and has cut off network connectivity, see RabbitMQ WebUI
          summary: RabbitMQ is Out of Disk Space
      - alert: RabbitMqMemoryAlarm
        expr: rabbitmq_node_mem_free_alarm == 1
        for: 1m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} High Memory Alarm is going off.  Which means the node hit highwater mark and has cut off network connectivity, see RabbitMQ WebUI
          summary: RabbitMQ is Out of Memory
      - alert: RabbitMqMemoryUsageHigh
        expr: (rabbitmq_node_mem_used / rabbitmq_node_mem_limit) > .9
        for: 1m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} Memory Usage > 90%
          summary: RabbitMQ Node > 90% Memory Usage
      - alert: RabbitMqFileDescriptorsLow
        expr: (rabbitmq_fd_used / rabbitmq_fd_total) > .9
        for: 5m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} File Descriptor Usage > 90%
          summary: RabbitMQ Low File Descriptor Available
      - alert: RabbitMqDiskSpaceLow
        expr: predict_linear(rabbitmq_node_disk_free[15m], 1 * 60 * 60) < rabbitmq_node_disk_free_limit
        for: 5m
        labels:
          installed_by: {{ .Release.Name }}
          severity: critical
{{- if .Values.prometheus.operator.alerts.labels }}
{{ toYaml .Values.prometheus.operator.alerts.labels | indent 10 }}
{{- end }}
        annotations:
          description: RabbitMQ {{`{{ $labels.namespace }}`}}/{{`{{ $labels.pod}}`}} will hit disk limit in the next hr based on last 15 mins trend.
          summary: RabbitMQ is Low on Disk Space and will Run Out in the next hour
{{ end }}
