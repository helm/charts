** Please be patient while the chart is being deployed **

{{- if or (contains .Values.clientService.type "LoadBalancer") (contains .Values.clientService.type "nodePort") }}
{{- if not .Values.auth.enabled }}
{{ if and (not .Values.networkPolicy.enabled) (.Values.networkPolicy.allowExternal) }}

-------------------------------------------------------------------------------
 WARNING

    By specifying "clientService.type=NodePort/LoadBalancer" and "auth.enabled=false"
    you have most likely exposed the NATS service externally without any authentication
    mechanism.

    For security reasons, we strongly suggest that you switch to "ClusterIP". As
    alternative, you can also switch to "auth.enabled=true" providing a valid
    password on "auth.password" parameter.

-------------------------------------------------------------------------------
{{- end }}
{{- end }}
{{- end }}

NATS can be accessed via port {{ .Values.clientService.port }} on the following DNS name from within your cluster:

   {{ template "nats.fullname" . }}-client.{{ .Release.Namespace }}.svc.cluster.local

{{- if .Values.auth.enabled }}
To get the authentication credentials, run:

    export NATS_USER=$(kubectl get cm --namespace {{ .Release.Namespace }} {{ template "nats.fullname" . }} -o jsonpath='{.data.*}' | grep -m 1 user | awk '{print $2}')
    export NATS_PASS=$(kubectl get cm --namespace {{ .Release.Namespace }} {{ template "nats.fullname" . }} -o jsonpath='{.data.*}' | grep -m 1 password | awk '{print $2}')
    echo -e "Client credentials:\n\tUser: $NATS_USER\n\tPassword: $NATS_PASS"

{{- end }}

NATS monitoring service can be accessed via port {{ .Values.monitoringService.port }} on the following DNS name from within your cluster:

   {{ template "nats.fullname" . }}-monitoring.{{ .Release.Namespace }}.svc.cluster.local

To access the Monitoring svc from outside the cluster, follow the steps below:

{{- if .Values.ingress.enabled }}

1. Get the hostname indicated on the Ingress Rule and associate it to your cluster external IP:

   export CLUSTER_IP=$(minikube ip) # On Minikube. Use: `kubectl cluster-info` on others K8s clusters
   export HOSTNAME=$(kubectl get ingress --namespace {{ .Release.Namespace }} {{ template "nats.fullname" . }}-monitoring -o jsonpath='{.spec.rules[0].host}')
   echo "Monitoring URL: http://$HOSTNAME/"
   echo "$CLUSTER_IP  $HOSTNAME" | sudo tee -a /etc/hosts

2. Open a browser and access the NATS monitoring browsing to the Monitoring URL

{{- else }}

1. Get the NATS monitoring URL by running:

{{- if contains "NodePort" .Values.monitoringService.type }}

    export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
    export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ template "nats.fullname" . }}-monitoring)
    echo "Monitoring URL: http://$NODE_IP:$NODE_PORT/"
{{- else if contains "LoadBalancer" .Values.monitoringService.type }}

  NOTE: It may take a few minutes for the LoadBalancer IP to be available.
        Watch the status with: 'kubectl get svc --namespace {{ .Release.Namespace }} -w {{ template "nats.fullname" . }}-monitoring'

    export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ template "nats.fullname" . }}-monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
    echo "Monitoring URL: http://$SERVICE_IP/"
{{- else if contains "ClusterIP" .Values.monitoringService.type }}

    export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l "app={{ template "nats.name" . }}" -o jsonpath="{.items[0].metadata.name}")
    echo "Monitoring URL: http://127.0.0.1:{{ .Values.monitoringService.port }}"
    kubectl port-forward --namespace {{ .Release.Namespace }} $POD_NAME {{ .Values.monitoringService.port }}:{{ .Values.monitoringService.port }}
{{- end }}

2. Access the NATS monitoring opening the URL obtained on a browser.
{{- end }}
