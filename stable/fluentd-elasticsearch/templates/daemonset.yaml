apiVersion: apps/v1beta2
kind: DaemonSet
metadata:
  name: {{ template "fluentd-elasticsearch.fullname" . }}
  labels:
    app: {{ template "fluentd-elasticsearch.fullname" . }}
    version: {{ .Values.image.tag }}
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
    heritage: "{{ .Release.Service }}"
    release: "{{ .Release.Name }}"
spec:
  selector:
    matchLabels:
      app: {{ template "fluentd-elasticsearch.fullname" . }}
      release: "{{ .Release.Name }}"
  template:
    metadata:
      labels:
        app: {{ template "fluentd-elasticsearch.fullname" . }}
        version: {{ .Values.image.tag }}
        chart: "{{ .Chart.Name }}-{{ .Chart.Version }}"
        heritage: "{{ .Release.Service }}"
        kubernetes.io/cluster-service: "true"
        version: {{ .Values.image.tag }}
        release: "{{ .Release.Name }}"
      # This annotation ensures that fluentd does not get evicted if the node
      # supports critical pod annotation based priority scheme.
      # Note that this does not guarantee admission on the nodes (#40573).
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
        checksum/config: {{ include (print $.Template.BasePath "/configmap.yaml") . | sha256sum }}
{{- if .Values.annotations }}
{{ toYaml .Values.annotations | indent 8 }}
{{- end }}
    spec:
      serviceAccountName: {{ template "fluentd-elasticsearch.fullname" . }}
      containers:
      - name: {{ template "fluentd-elasticsearch.fullname" . }}
        image:  "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.imagePullPolicy | quote }}
        env:
        - name: FLUENTD_ARGS
          value: --no-supervisor -q
        - name: OUTPUT_HOST
          value: {{ .Values.elasticsearch.host | quote }}
        - name: OUTPUT_PORT
          value: {{ .Values.elasticsearch.port | quote }}
        - name: LOGSTASH_PREFIX
          value: {{ .Values.elasticsearch.logstash_prefix | quote }}
        - name: OUTPUT_BUFFER_CHUNK_LIMIT
          value: {{ .Values.elasticsearch.buffer_chunk_limit | quote }}
        - name: OUTPUT_BUFFER_QUEUE_LIMIT
          value: {{ .Values.elasticsearch.buffer_queue_limit | quote }}
        - name: K8S_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        resources:
{{ toYaml .Values.resources | indent 10 }}
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: libsystemddir
          mountPath: /host/lib
          readOnly: true
        - name: config-volume
          mountPath: /etc/fluent/config.d
{{- if .Values.extraVolumeMounts }}
{{ toYaml .Values.extraVolumeMounts | indent 8 }}
{{- end }}
        ports:
{{- range $port := .Values.service.ports }}
          - name: {{ $port.name }}
            containerPort: {{ $port.port }}
{{- if $port.protocol }}
            protocol: {{ $port.protocol }}
{{- end }}
{{- end }}
{{- if .Values.livenessProbe.enabled }}
        # Liveness probe is aimed to help in situarions where fluentd
        # silently hangs for no apparent reasons until manual restart.
        # The idea of this probe is that if fluentd is not queueing or
        # flushing chunks for 5 minutes, something is not right. If
        # you want to change the fluentd configuration, reducing amount of
        # logs fluentd collects, consider changing the threshold or turning
        # liveness probe off completely.
        livenessProbe:
          initialDelaySeconds: 600
          periodSeconds: 60
          exec:
            command:
            - '/bin/sh'
            - '-c'
            - >
              LIVENESS_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-300};
              STUCK_THRESHOLD_SECONDS=${LIVENESS_THRESHOLD_SECONDS:-900};
              if [ ! -e /var/log/fluentd-buffers ];
              then
                exit 1;
              fi;
              touch -d "${STUCK_THRESHOLD_SECONDS} seconds ago" /tmp/marker-stuck;
              if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-stuck -print -quit)" ]];
              then
                rm -rf /var/log/fluentd-buffers;
                exit 1;
              fi;
              touch -d "${LIVENESS_THRESHOLD_SECONDS} seconds ago" /tmp/marker-liveness;
              if [[ -z "$(find /var/log/fluentd-buffers -type f -newer /tmp/marker-liveness -print -quit)" ]];
              then
                exit 1;
              fi;
{{- end }}
      terminationGracePeriodSeconds: 30
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      # It is needed to copy systemd library to decompress journals
      - name: libsystemddir
        hostPath:
          path: /usr/lib64
      - name: config-volume
        configMap:
          name: {{ template "fluentd-elasticsearch.fullname" . }}
{{- if .Values.extraVolumes }}
{{ toYaml .Values.extraVolumes | indent 6 }}
{{- end }}
{{- if .Values.nodeSelector }}
      nodeSelector:
{{ toYaml .Values.nodeSelector | indent 8 }}
{{- end }}
{{- if .Values.tolerations }}
      tolerations:
{{ toYaml .Values.tolerations | indent 6 }}
{{- end }}
