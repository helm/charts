{"paragraphs":[{"user":"anonymous","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549560881266_-1396707350","id":"paragraph_1549560881266_-1396707350","dateCreated":"2019-02-07T17:35:07+0000","status":"READY","focus":true,"$$hashKey":"object:7074","text":"%spark.dep\n// include the azure mmlspark dependency\nz.reset()\nz.load(\"Azure:mmlspark:0.15\")\nz.load(\"org.apache.hadoop:hadoop-azure:2.7.0\")\nz.load(\"com.microsoft.azure:azure-storage:8.0.0\")","runtimeInfos":{}},{"text":"%md\r\n## 103 - Simplifying Machine Learning Pipelines with `mmlspark`\r\n\r\n### 1. Introduction\r\n\r\n<p><img src=\"https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg\" style=\"width: 500px;\" title=\"Image from https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg\" /><br /></p>\r\n\r\nIn this tutorial, we perform the same classification task in two different ways: once using plain **`pyspark`** and once using the **`mmlspark`** library.  The two methods yield the same performance, but one of the two libraries is drastically simpler to use and iterate on (can you guess which one?).\r\n\r\nThe task is simple: Predict whether a user's review of a book sold on Amazon is good (rating > 3) or bad based on the text of the review.  We accomplish this by training LogisticRegression learners with different hyperparameters and choosing the best model.","user":"anonymous","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549560907558_-1510106009","id":"paragraph_1549560907558_-1510106009","dateCreated":"2019-02-07T17:35:52+0000","status":"FINISHED","focus":true,"$$hashKey":"object:7270","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>103 - Simplifying Machine Learning Pipelines with <code>mmlspark</code></h2>\n<h3>1. Introduction</h3>\n<p><img src=\"https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg\" style=\"width: 500px;\" title=\"Image from https://images-na.ssl-images-amazon.com/images/G/01/img16/books/bookstore/landing-page/1000638_books_landing-page_bookstore-photo-01.jpg\" /><br /></p>\n<p>In this tutorial, we perform the same classification task in two different ways: once using plain <strong><code>pyspark</code></strong> and once using the <strong><code>mmlspark</code></strong> library. The two methods yield the same performance, but one of the two libraries is drastically simpler to use and iterate on (can you guess which one?).</p>\n<p>The task is simple: Predict whether a user&rsquo;s review of a book sold on Amazon is good (rating &gt; 3) or bad based on the text of the review. We accomplish this by training LogisticRegression learners with different hyperparameters and choosing the best model.</p>\n</div>"}]},"runtimeInfos":{}},{"text":"%md\r\n### 2. Read the data\r\n\r\nWe download and read in the data. We show a sample below:","user":"anonymous","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549560950666_-2091601662","id":"paragraph_1549560950666_-2091601662","dateCreated":"2019-02-07T17:36:11+0000","status":"FINISHED","focus":true,"$$hashKey":"object:7361","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>2. Read the data</h3>\n<p>We download and read in the data. We show a sample below:</p>\n</div>"}]},"runtimeInfos":{}},{"text":"%pyspark\n# Zeppelin needs the path to be update manually to find mmlspark library\nimport sys\nsys.path.extend(sc.getConf().get(\"spark.jars\").split(\",\"))\n\nimport pandas as pd\nimport mmlspark\nfrom pyspark.sql.types import IntegerType, StringType, StructType, StructField\n\ndataFilePath = \"BookReviewsFromAmazon10K.tsv\"\ntextSchema = StructType([StructField(\"rating\", IntegerType(), False),\n                         StructField(\"text\", StringType(), False)])\nimport os, urllib\nif not os.path.isfile(dataFilePath):\n    urllib.urlretrieve(\"https://mmlspark.azureedge.net/datasets/\" + dataFilePath, dataFilePath)\nrawData = spark.createDataFrame(pd.read_csv(dataFilePath, sep=\"\\t\", header=None), textSchema)\nrawData.show(5)\n","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549560971147_-312816441","id":"paragraph_1549560971147_-312816441","dateCreated":"2019-02-07T17:36:26+0000","status":"READY","focus":true,"$$hashKey":"object:7460","runtimeInfos":{}},{"text":"%md\n### 3. Extract more features and process data\n\nReal data however is more complex than the above dataset. It is common for a dataset to have features of multiple types: text, numeric, categorical.  To illustrate how difficult it is to work with these datasets, we add two numerical features to the dataset: the **word count** of the review and the **mean word length**.","user":"anonymous","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561045867_-2023351219","id":"paragraph_1549561045867_-2023351219","dateCreated":"2019-02-07T17:37:29+0000","status":"FINISHED","focus":true,"$$hashKey":"object:7616","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>3. Extract more features and process data</h3>\n<p>Real data however is more complex than the above dataset. It is common for a dataset to have features of multiple types: text, numeric, categorical. To illustrate how difficult it is to work with these datasets, we add two numerical features to the dataset: the <strong>word count</strong> of the review and the <strong>mean word length</strong>.</p>\n</div>"}]},"runtimeInfos":{}},{"text":"%pyspark\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import LongType, FloatType, DoubleType\ndef wordCount(s):\n    return len(s.split())\ndef wordLength(s):\n    import numpy as np\n    ss = [len(w) for w in s.split()]\n    return round(float(np.mean(ss)), 2)\nwordLengthUDF = udf(wordLength, DoubleType())\nwordCountUDF = udf(wordCount, IntegerType())","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549560986476_-857211016","id":"paragraph_1549560986476_-857211016","dateCreated":"2019-02-07T17:37:10+0000","status":"READY","focus":true,"$$hashKey":"object:7544","runtimeInfos":{}},{"text":"%pyspark\nfrom mmlspark import UDFTransformer\nwordLength = \"wordLength\"\nwordCount = \"wordCount\"\nwordLengthTransformer = UDFTransformer(inputCol=\"text\", outputCol=wordLength, udf=wordLengthUDF)\nwordCountTransformer = UDFTransformer(inputCol=\"text\", outputCol=wordCount, udf=wordCountUDF)","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561076902_257402397","id":"paragraph_1549561076902_257402397","dateCreated":"2019-02-07T17:38:04+0000","status":"READY","focus":true,"$$hashKey":"object:7706","runtimeInfos":{}},{"text":"%pyspark\nfrom pyspark.ml import Pipeline\ndata = Pipeline(stages=[wordLengthTransformer, wordCountTransformer]) \\\n       .fit(rawData).transform(rawData) \\\n       .withColumn(\"label\", rawData[\"rating\"] > 3).drop(\"rating\")","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561091918_-2108761101","id":"paragraph_1549561091918_-2108761101","dateCreated":"2019-02-07T17:38:16+0000","status":"READY","focus":true,"$$hashKey":"object:7778","runtimeInfos":{}},{"text":"%md\n### 4a. Classify using pyspark\n\nTo choose the best LogisticRegression classifier using the `pyspark` library, need to *explictly* perform the following steps:\n\n1. Process the features:\n   * Tokenize the text column\n   * Hash the tokenized column into a vector using hashing\n   * Merge the numeric features with the vector in the step above\n2. Process the label column: cast it into the proper type.\n3. Train multiple LogisticRegression algorithms on the `train` dataset with different hyperparameters\n4. Compute the area under the ROC curve for each of the trained models and select the model with the highest metric as computed on the `test` dataset\n5. Evaluate the best model on the `validation` set\n\nAs you can see below, there is a lot of work involved and a lot of steps where something can go wrong!","user":"anonymous","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561105519_758143693","id":"paragraph_1549561105519_758143693","dateCreated":"2019-02-07T17:38:35+0000","status":"READY","focus":true,"$$hashKey":"object:7850","runtimeInfos":{}},{"text":"%pyspark\nfrom pyspark.ml.feature import Tokenizer, HashingTF\nfrom pyspark.ml.feature import VectorAssembler\n\n# Featurize text column\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokenizedText\")\nnumFeatures = 10000\nhashingScheme = HashingTF(inputCol=\"tokenizedText\",\n                          outputCol=\"TextFeatures\",\n                          numFeatures=numFeatures)\ntokenizedData = tokenizer.transform(data)\nfeaturizedData = hashingScheme.transform(tokenizedData)\n\n# Merge text and numeric features in one feature column\nfeatureColumnsArray = [\"TextFeatures\", \"wordCount\", \"wordLength\"]\nassembler = VectorAssembler(\n    inputCols = featureColumnsArray,\n    outputCol=\"features\")\nassembledData = assembler.transform(featurizedData)\n\n# Select only columns of interest\n# Convert rating column from boolean to int\nprocessedData = assembledData \\\n                .select(\"label\", \"features\") \\\n                .withColumn(\"label\", assembledData.label.cast(IntegerType()))\n","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561123327_369147431","id":"paragraph_1549561123327_369147431","dateCreated":"2019-02-07T17:38:50+0000","status":"READY","focus":true,"$$hashKey":"object:7922","runtimeInfos":{}},{"text":"%pyspark\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.classification import LogisticRegression\n\n# Prepare data for learning\ntrain, test, validation = processedData.randomSplit([0.60, 0.20, 0.20], seed=123)\n\n# Train the models on the 'train' data\nlrHyperParams = [0.05, 0.1, 0.2, 0.4]\nlogisticRegressions = [LogisticRegression(regParam = hyperParam)\n                       for hyperParam in lrHyperParams]\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",\n                                          metricName=\"areaUnderROC\")\nmetrics = []\nmodels = []\n\n# Select the best model\nfor learner in logisticRegressions:\n    model = learner.fit(train)\n    models.append(model)\n    scoredData = model.transform(test)\n    metrics.append(evaluator.evaluate(scoredData))\nbestMetric = max(metrics)\nbestModel = models[metrics.index(bestMetric)]\n\n# Save model\nbestModel.write().overwrite().save(\"SparkMLExperiment.mmls\")\n# Get AUC on the validation dataset\nscoredVal = bestModel.transform(validation)\nprint(evaluator.evaluate(scoredVal))","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561136914_-1460942872","id":"paragraph_1549561136914_-1460942872","dateCreated":"2019-02-07T17:39:01+0000","status":"READY","focus":true,"$$hashKey":"object:7994","runtimeInfos":{}},{"text":"%md\n### 4b. Classify using mmlspark\n\nLife is a lot simpler when using `mmlspark`!\n\n1. The **`TrainClassifier`** Estimator featurizes the data internally,\n   as long as the columns selected in the `train`, `test`, `validation`\n   dataset represent the features\n\n2. The **`FindBestModel`** Estimator find the best model from a pool of\n   trained models by find the model which performs best on the `test`\n   dataset given the specified metric\n\n3. The **`CompueModelStatistics`** Transformer computes the different\n   metrics on a scored dataset (in our case, the `validation` dataset)\n   at the same time","user":"anonymous","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561151031_-669643989","id":"paragraph_1549561151031_-669643989","dateCreated":"2019-02-07T17:39:16+0000","status":"FINISHED","focus":true,"$$hashKey":"object:8066","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>4b. Classify using mmlspark</h3>\n<p>Life is a lot simpler when using <code>mmlspark</code>!</p>\n<ol>\n  <li>\n  <p>The <strong><code>TrainClassifier</code></strong> Estimator featurizes the data internally,<br/> as long as the columns selected in the <code>train</code>, <code>test</code>, <code>validation</code><br/> dataset represent the features</p></li>\n  <li>\n  <p>The <strong><code>FindBestModel</code></strong> Estimator find the best model from a pool of<br/> trained models by find the model which performs best on the <code>test</code><br/> dataset given the specified metric</p></li>\n  <li>\n  <p>The <strong><code>CompueModelStatistics</code></strong> Transformer computes the different<br/> metrics on a scored dataset (in our case, the <code>validation</code> dataset)<br/> at the same time</p></li>\n</ol>\n</div>"}]},"runtimeInfos":{}},{"text":"%pyspark\nfrom mmlspark import TrainClassifier, FindBestModel, ComputeModelStatistics\n\n# Prepare data for learning\ntrain, test, validation = data.randomSplit([0.60, 0.20, 0.20], seed=123)\n\n# Train the models on the 'train' data\nlrHyperParams = [0.05, 0.1, 0.2, 0.4]\nlogisticRegressions = [LogisticRegression(regParam = hyperParam)\n                       for hyperParam in lrHyperParams]\nlrmodels = [TrainClassifier(model=lrm, labelCol=\"label\", numFeatures=10000).fit(train)\n            for lrm in logisticRegressions]\n\n# Select the best model\nbestModel = FindBestModel(evaluationMetric=\"AUC\", models=lrmodels).fit(test)\n\n# Save model\nbestModel.write().overwrite().save(\"MMLSExperiment.mmls\")\n# Get AUC on the validation dataset\npredictions = bestModel.transform(validation)\nmetrics = ComputeModelStatistics().transform(predictions)\nprint(\"Best model's AUC on validation set = \"\n      + \"{0:.2f}%\".format(metrics.first()[\"AUC\"] * 100))","user":"anonymous","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"progressUpdateIntervalMs":500,"jobName":"paragraph_1549561156327_905971663","id":"paragraph_1549561156327_905971663","dateCreated":"2019-02-07T17:39:36+0000","status":"READY","focus":true,"$$hashKey":"object:8144","runtimeInfos":{}}],"name":"simplification_mmlspark","id":"2E3XBY5JN","defaultInterpreterGroup":"spark","noteParams":{},"noteForms":{},"angularObjects":{},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}